{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import models\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Checks the accuracy of the model on the given dataset loader.\n",
    "\n",
    "    Parameters:\n",
    "        loader: DataLoader\n",
    "            The DataLoader for the dataset to check accuracy on.\n",
    "        model: nn.Module\n",
    "            The neural network model.\n",
    "    \"\"\"\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            # Forward pass: compute the model output\n",
    "            scores = model(x)\n",
    "\n",
    "            _, predictions = scores.max(1)  # Get the index of the max log-probability\n",
    "            num_correct += (predictions == y).sum()  # Count correct predictions\n",
    "            num_samples += predictions.size(0)  # Count total samples\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = float(num_correct) / float(num_samples) * 100\n",
    "        print(f\"Got {num_correct}/{num_samples} with accuracy {accuracy:.2f}%\")\n",
    "    \n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "def train(train_loader, model):\n",
    "    '''\n",
    "    Trains the model \n",
    "\n",
    "    Parameters: \n",
    "        train_loader: DataLoader\n",
    "            The DataLoader for the dataset to perform training on\n",
    "        model: nn.Module\n",
    "            The neural network model\n",
    "    '''\n",
    "    #Hyperparameters\n",
    "    num_epochs = 100\n",
    "\n",
    "    #Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #Train the network\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "        for batch_index, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Reshape data to (batch_size, input_size), if it is directly fed into linear network\n",
    "            #data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "            # Forward pass: compute the model output\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            # Backward pass: compute the gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimization step: update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    # Set up device\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    #Define hyperparameters\n",
    "    input_height = 28  # Image height\n",
    "    input_width = 28 # Image width\n",
    "    num_classes = 10  # digits 0-9\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "\n",
    "    #Load data\n",
    "    train_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=True, transform=transforms.ToTensor())\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = datasets.MNIST(root=\"dataset/\", download=True, train=False, transform=transforms.ToTensor())\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #Initialize the network\n",
    "    model = models.NNConvolutionalOneHiddenLayer(28,28, num_classes=num_classes).to(device)\n",
    "\n",
    "    #Train model\n",
    "    train(train_loader, model)\n",
    "    \n",
    "    #Final accuracy check on training and test sets\n",
    "    check_accuracy(train_loader, model)\n",
    "    check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
